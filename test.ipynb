{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3853ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ahmed\\anaconda3\\envs\\education\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import chromadb\n",
    "import google.generativeai as genai\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198187bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "genai.configure(api_key=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51b8727a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def extract_and_chunk_pdf(file):\n",
    "    reader = PdfReader(file)\n",
    "    text = \"\\n\".join([page.extract_text() for page in reader.pages if page.extract_text()])\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    chunks = splitter.split_text(text)\n",
    "    return chunks\n",
    "\n",
    " # run this function on all files that ends with .pdf on the directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51edff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def extract_and_chunk_pdfs_from_dir(directory_path):\n",
    "    all_chunks = []\n",
    "    \n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            with open(file_path, \"rb\") as file:\n",
    "                chunks = extract_and_chunk_pdf(file)\n",
    "                all_chunks.extend(chunks)\n",
    "    \n",
    "    return all_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30a8f376",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=extract_and_chunk_pdfs_from_dir(r\"./pdf\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6f6de53",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents= b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "666c24f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb import EmbeddingFunction\n",
    "from google.generativeai import embed_content\n",
    "\n",
    "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
    "    document_mode = True\n",
    "\n",
    "    def __call__(self, input: list[str]) -> list[list[float]]:\n",
    "        task = \"retrieval_document\" if self.document_mode else \"retrieval_query\"\n",
    "        embeddings = []\n",
    "\n",
    "        for text in input:\n",
    "            try:\n",
    "                response = embed_content(\n",
    "                    model=\"models/embedding-001\",\n",
    "                    content=text,\n",
    "                    task_type=task,\n",
    "                )\n",
    "                embeddings.append(response[\"embedding\"])\n",
    "            except Exception as e:\n",
    "                print(f\"Error embedding: {e}\")\n",
    "                embeddings.append([0.0] * 768)  # fallback vector\n",
    "\n",
    "        return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "155b68c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed\\AppData\\Local\\Temp\\ipykernel_15296\\3056851207.py:5: DeprecationWarning: The class GeminiEmbeddingFunction does not implement __init__. This will be required in a future version.\n",
      "  embed_fn = GeminiEmbeddingFunction()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'white_papers_db' initialized successfully.\n",
      "Documents added successfully.\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "DB_NAME = \"white_papers_db\"\n",
    "\n",
    "embed_fn = GeminiEmbeddingFunction()\n",
    "embed_fn.document_mode = True\n",
    "\n",
    "\n",
    "try:\n",
    "\tchroma_client = chromadb.PersistentClient(path=\"./chroma_db\")  \n",
    "\tdb = chroma_client.get_or_create_collection(name=DB_NAME, embedding_function=embed_fn)\n",
    "\tprint(f\"Collection '{DB_NAME}' initialized successfully.\")\n",
    "except Exception as e:\n",
    "\tprint(f\"Error initializing database or collection: {e}\")\n",
    "\traise\n",
    "\n",
    "# Add documents to the collection\n",
    "try:\n",
    "\tdb.add(documents=documents, ids=[str(i) for i in range(len(documents))])\n",
    "\tprint(\"Documents added successfully.\")\n",
    "except Exception as e:\n",
    "\tprint(f\"Error adding documents to the collection: {e}\")\n",
    "\traise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b181bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'white_papers_db'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62294d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2801afb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdb\u001b[49m.count()  \u001b[38;5;66;03m# Check the number of documents in the collection\u001b[39;00m\n\u001b[32m      2\u001b[39m db.peek(\u001b[32m3\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'db' is not defined"
     ]
    }
   ],
   "source": [
    "# get db name \n",
    "\n",
    "db.count()  # Check the number of documents in the collection\n",
    "db.peek(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c307e857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Keeping. Would you like me to walk you through the settings menu instead?\"\n",
       "General Knowledge Agent\n",
       "The General Knowledge Agent is specialized in answering factual questions about the world, \n",
       "history, science, culture, and other general topics. This agent accesses a broad knowledge \n",
       "base to answer factual questions, provides biographical information about people, offers \n",
       "contextual explanations of concepts and phenomena, maintains grounding in factual"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "embed_fn.document_mode = False\n",
    "\n",
    "# Search the Chroma DB using the specified query.\n",
    "query = \"hi\"\n",
    "\n",
    "result = db.query(query_texts=[query], n_results=1)\n",
    "[all_passages] = result[\"documents\"]\n",
    "\n",
    "Markdown(all_passages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b50c2024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful and informative and conversational bot for university students that answers questions and explain concepts using text from the reference passage included below. \n",
      "you can use other information from your own knowledge only if it is necessary to ensure the answer is correct and complete.\n",
      "Be sure to respond in a complete sentence, being comprehensive, including all relevant background information. \n",
      "However, you are talking to a non-technical audience, so be sure to break down complicated concepts and \n",
      "strike a friendly and converstional tone and act like human. If the passage is irrelevant to the answer, you may ignore it.\n",
      "\n",
      "QUESTION: hi\n",
      "PASSAGE: Keeping. Would you like me to walk you through the settings menu instead?\" General Knowledge Agent The General Knowledge Agent is specialized in answering factual questions about the world,  history, science, culture, and other general topics. This agent accesses a broad knowledge  base to answer factual questions, provides biographical information about people, offers  contextual explanations of concepts and phenomena, maintains grounding in factual\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_oneline = query.replace(\"\\n\", \" \")\n",
    "\n",
    "# This prompt is where you can specify any guidance on tone, or what topics the model should stick to, or avoid.\n",
    "prompt = f\"\"\"You are a helpful and informative and conversational bot for university students that answers questions and explain concepts using text from the reference passage included below. \n",
    "you can use other information from your own knowledge only if it is necessary to ensure the answer is correct and complete.\n",
    "Be sure to respond in a complete sentence, being comprehensive, including all relevant background information. \n",
    "However, you are talking to a non-technical audience, so be sure to break down complicated concepts and \n",
    "strike a friendly and converstional tone and act like human. If the passage is irrelevant to the answer, you may ignore it.\n",
    "\n",
    "QUESTION: {query_oneline}\n",
    "\"\"\"\n",
    "\n",
    "# Add the retrieved documents to the prompt.\n",
    "for passage in all_passages:\n",
    "    passage_oneline = passage.replace(\"\\n\", \" \")\n",
    "    prompt += f\"PASSAGE: {passage_oneline}\\n\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "61ae16f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hi there! How can I help you today? I'm here to answer your questions and explain concepts in a way that's easy to understand. Just let me know what you're curious about!\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "\n",
    "# Generate content\n",
    "response = model.generate_content(prompt)\n",
    "\n",
    "# Display the response as Markdown\n",
    "Markdown(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "education",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
